{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQsksDwwjAUx",
        "outputId": "99f18d5c-5cf3-4a61-eba0-c420b52dfb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'The': 0, 'a': 1, 'brown': 2, 'dog': 3, 'fox': 4, 'jumps': 5, 'lazy': 6, 'over': 7, 'quick': 8}\n"
          ]
        }
      ],
      "source": [
        "sentence = 'The quick brown fox jumps over a lazy dog'\n",
        "dc = {s: i for i, s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
        "print(dc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://mohdfaraaz.medium.com/implementing-self-attention-from-scratch-in-pytorch-776ef7b8f13e"
      ],
      "metadata": {
        "id": "GGdjl0xYqOmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "q_HWIabgmkTd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sort all the words and assign indices to each word"
      ],
      "metadata": {
        "id": "i9jZT3WWoazO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = [dc[i] for i in sentence.replace(',', '').split()]\n",
        "print(r)\n",
        "sentence_int = torch.tensor(r)\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49LVYzjKjBi5",
        "outputId": "a38a1dcd-ccf6-4b25-eafa-127652b434f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 8, 2, 4, 5, 7, 1, 6, 3]\n",
            "tensor([0, 8, 2, 4, 5, 7, 1, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, take the initial sentence and replace with indices that were assigned according to sorted order"
      ],
      "metadata": {
        "id": "h5Rk0qjFomoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "3WsuO-ekmiYi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50000  # Assume a large vocabulary size\n",
        "torch.manual_seed(123)\n",
        "embed = nn.Embedding(vocab_size, 3)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcuwSDPzo5st",
        "outputId": "e8ae5d40-0071-4081-8f6e-da7af0a4ba76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3374, -0.1778, -0.3035],\n",
            "        [ 0.4965, -1.5723,  0.9666],\n",
            "        [-0.2196, -0.3792,  0.7671],\n",
            "        [ 0.1794,  1.8951,  0.4954],\n",
            "        [ 0.2692, -0.0770, -1.0205],\n",
            "        [ 1.3010,  1.2753, -0.2010],\n",
            "        [-0.5880,  0.3486,  0.6603],\n",
            "        [-0.1690,  0.9178,  1.5810],\n",
            "        [-1.1925,  0.6984, -1.4097]])\n",
            "torch.Size([9, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-Attention Mechanism\n",
        "We transform the embedded sentence to apply self-attention, starting by creating query, key, and value matrices."
      ],
      "metadata": {
        "id": "oMS9kRZ2z2_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "d = embedded_sentence.shape[1]  # Dimension of embeddings\n",
        "d_q, d_k, d_v = 2, 2, 4  # Dimensions for query, key, and value matrices"
      ],
      "metadata": {
        "id": "PfaFSS7ApRbc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHJsWV-I0YAt",
        "outputId": "0ffa0ae8-f2ad-4ed0-ead4-63dfe5ff0169"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W_query = torch.nn.Parameter(torch.rand(d, d_q))\n",
        "W_key = torch.nn.Parameter(torch.rand(d, d_k))\n",
        "W_value = torch.nn.Parameter(torch.rand(d, d_v))\n",
        "query = embedded_sentence @ W_query\n",
        "key = embedded_sentence @ W_key\n",
        "value = embedded_sentence @ W_value"
      ],
      "metadata": {
        "id": "9sWdrwKbz7Lh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "zSuLFeGp0CKJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = query @ key.T\n",
        "attention_scores = attention_scores / math.sqrt(d_k)\n",
        "attention_weights = F.softmax(attention_scores, dim=-1)"
      ],
      "metadata": {
        "id": "eoGUfyhwpcop"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXY304xkpiNR",
        "outputId": "e15a54f0-d4fc-4fad-9b06-599b1d99ea9e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1211, 0.1238, 0.1124, 0.0906, 0.1284, 0.1019, 0.1058, 0.0908, 0.1251],\n",
            "        [0.1133, 0.1108, 0.1106, 0.1067, 0.1160, 0.1084, 0.1103, 0.1051, 0.1188],\n",
            "        [0.0972, 0.0936, 0.1066, 0.1411, 0.0904, 0.1210, 0.1157, 0.1400, 0.0944],\n",
            "        [0.0195, 0.0178, 0.0425, 0.3473, 0.0103, 0.1129, 0.0743, 0.3637, 0.0116],\n",
            "        [0.1435, 0.1536, 0.1060, 0.0451, 0.1829, 0.0715, 0.0837, 0.0450, 0.1688],\n",
            "        [0.0311, 0.0299, 0.0582, 0.3047, 0.0185, 0.1264, 0.0896, 0.3223, 0.0195],\n",
            "        [0.0837, 0.0797, 0.1007, 0.1713, 0.0722, 0.1285, 0.1169, 0.1708, 0.0764],\n",
            "        [0.0195, 0.0171, 0.0421, 0.3513, 0.0105, 0.1124, 0.0749, 0.3599, 0.0123],\n",
            "        [0.1524, 0.1661, 0.0874, 0.0191, 0.2395, 0.0432, 0.0580, 0.0186, 0.2158]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector = attention_weights @ value\n",
        "print(context_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNmYvgHFpmcg",
        "outputId": "98c1476b-bb3f-488e-a160-0e4513b33150"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1161,  0.2648,  0.1661,  0.2705],\n",
            "        [ 0.1610,  0.3502,  0.2213,  0.3606],\n",
            "        [ 0.2796,  0.5341,  0.3544,  0.5734],\n",
            "        [ 0.8153,  1.4165,  0.9633,  1.5575],\n",
            "        [-0.0840, -0.0267, -0.0515, -0.0758],\n",
            "        [ 0.7347,  1.2733,  0.8703,  1.4049],\n",
            "        [ 0.3734,  0.6840,  0.4609,  0.7442],\n",
            "        [ 0.8109,  1.4172,  0.9614,  1.5550],\n",
            "        [-0.2663, -0.2382, -0.2310, -0.3559]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d, d_q, d_k, d_v):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.d = d\n",
        "        self.d_q = d_q\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.W_query = nn.Parameter(torch.rand(d, d_q))\n",
        "        self.W_key = nn.Parameter(torch.rand(d, d_k))\n",
        "        self.W_value = nn.Parameter(torch.rand(d, d_v))\n",
        "    def forward(self, x):\n",
        "        Q = x @ self.W_query\n",
        "        K = x @ self.W_key\n",
        "        V = x @ self.W_value\n",
        "        attention_scores = Q @ K.T / math.sqrt(self.d_k)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "        context_vector = attention_weights @ V\n",
        "        return context_vector"
      ],
      "metadata": {
        "id": "pPfYU97qptJl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sa = SelfAttention(d=3, d_q=2, d_k=2, d_v=4)\n",
        "cv = sa(embedded_sentence)\n",
        "print(cv.shape)\n",
        "print(cv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZDoHvsap3XT",
        "outputId": "0f19d7d5-1323-4b04-f9f5-8220c86a1af0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 4])\n",
            "tensor([[ 0.1298,  0.0803,  0.1391,  0.2768],\n",
            "        [ 0.1655,  0.1568,  0.1631,  0.2725],\n",
            "        [ 0.3061,  0.2906,  0.3173,  0.5926],\n",
            "        [ 0.7892,  0.7268,  0.8756,  1.8529],\n",
            "        [-0.1215, -0.2569, -0.1180, -0.1904],\n",
            "        [ 0.7618,  0.7043,  0.8472,  1.7998],\n",
            "        [ 0.4224,  0.3984,  0.4465,  0.8663],\n",
            "        [ 0.7982,  0.7307,  0.8705,  1.7889],\n",
            "        [-0.3056, -0.5724, -0.3023, -0.5099]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxWxDQEGp6IR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}